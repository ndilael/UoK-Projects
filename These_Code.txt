/*
 * Created by Maurice NDIZEYE
 */
import threading
from flask import Flask, render_template, Response, request, jsonify, redirect, url_for
from aiortc import RTCPeerConnection, RTCSessionDescription
import cv2
import json
import uuid
import asyncio
import torch
import numpy as np
from collections import defaultdict
from flask_socketio import SocketIO
from pydub import AudioSegment
import simpleaudio as sa
import time

# Create a Flask app instance
app = Flask(__name__, static_url_path='/static')
# Set to keep track of RTCPeerConnection instancesls
pcs = set()
socketio = SocketIO(app)

# Path to the alarm sound
path_alarm = "Alarm/alarm1.wav"
alarm_sound = AudioSegment.from_wav('Alarm/alarm1.wav')

count = 0
# Loading the model
# model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=False)
model = torch.hub.load('ultralytics/yolov5', 'custom',
                       path='/Users/mauro/Desktop/Model_Training/CCTV/ultralytics/yolov5/runs/train/exp/weights/last.pt',
                       force_reload=True)
# cap = cv2.VideoCapture("rtsp://admin:Drd@123456@10.0.10.44")
cap = cv2.VideoCapture("Test Videos/thief_video4.mp4")

target_classes = ['person', 'suspect', 'vehicle', 'animal']
count = 0
number_of_photos = 3

# Polygon points
pts = []

# Function to draw polygon(roi)
def draw_polygon(event, x, y, flags, param):
    global pts
    if event == cv2.EVENT_LBUTTONDOWN:
        print(x, y)
        pts.append([x, y])
    elif event == cv2.EVENT_RBUTTONDOWN:
        pts = []

def convert_numpy_float(obj):
    if isinstance(obj, np.float32):
        return float(obj)
    return obj
# Function to check if a point is inside a polygon
def inside_polygon(point, polygon):
    result = cv2.pointPolygonTest(polygon, (point[0], point[1]), False)
    if result == 1:
        return True
    else:
        return False
audio_playback = None

def play_alarm():
    global audio_playback
    audio_playback = sa.play_buffer(alarm_sound.raw_data, num_channels=alarm_sound.channels,
                                    bytes_per_sample=alarm_sound.sample_width,
                                    sample_rate=alarm_sound.frame_rate)

cv2.namedWindow('Video')
cv2.setMouseCallback('Video', draw_polygon)

def preprocess(img):
    height, width = img.shape[:2]
   ratio = height / width

    img = cv2.resize(img, (640, int(640 * ratio)))
    return img
target_counts = defaultdict(lambda: {"count": 0})

# Function to generate video frames from the camera
def generate_frames():
    # camera = cv2.VideoCapture(0)
    global count
    global target_counts
    while True:
        ret, frame = cap.read()
        frame_detected = frame.copy()

        frame = preprocess(frame)

        results = model(frame)
        target_counts.clear()

        # using panda to get the detected objects' data
        for index, row in results.pandas().xyxy[0].iterrows():
            center_x = None
            center_y = None

            if row['name'] in target_classes:
                name = str(row['name'])
                target_counts[name]['count'] += 1
                if name == 'suspect':
                    # Start playback in a new thread
                    threading.Thread(target=play_alarm).start()

                    # Stop audio playback at the end of the frame (e.g., after 1/30 second)
                    time.sleep(1 / 30)  # Simulate the frame duration
                    if audio_playback:
                        audio_playback.stop()
                x1 = int(row['xmin'])
                y1 = int(row['ymin'])
                x2 = int(row['xmax'])
                y2 = int(row['ymax'])

                center_x = int((x1 + x2) / 2)

                center_y = int((y1 + y2) / 2)
                # draw bounding box
                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 255, 0), 3)
                # write name
                cv2.putText(frame, name, (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)
                # draw center
                cv2.circle(frame, (center_x, center_y), 5, (0, 0, 255), -1)

            # Drawing the polygon
            if len(pts) >= 4:
                frame_copy = frame.copy()
                cv2.fillPoly(frame_copy, np.array([pts]), (0, 255, 0))
                frame = cv2.addWeighted(frame_copy, 0.1, frame, 0.9, 0)
                if center_x is not None and center_y is not None:

                    # Checking if the center of the object is inside the polygon and if the object is a person
                    if inside_polygon((center_x, center_y), np.array([pts])) and name == 'suspect':
                        mask = np.zeros_like(frame_detected)
                        points = np.array([[x1, y1], [x1, y2], [x2, y2], [x2, y1]])
                        points = points.reshape((-1, 1, 2))
                        mask = cv2.fillPoly(mask, [points], (255, 255, 255))
                        frame_detected = cv2.bitwise_and(frame_detected, mask)
                        # Saving the detected image
                        if count < number_of_photos:
                            cv2.imwrite("Detected Photos/detected" + str(count) + ".jpg", frame_detected)
                        # Playing the alarm
                        if not pygame.mixer.music.get_busy():
                            pygame.mixer.music.play()
                            alarm_playing = True
                        cv2.putText(frame, "Target", (center_x, center_y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                        cv2.putText(frame, "Suspect Detected", (20, 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 3)
                        count += 1
            # print(target_counts)
            cv2.imshow("", frame)
        ret, buffer = cv2.imencode('.jpg', frame)
        buffer_bytes = buffer.tobytes()
        # Concatenate frame and yield for streaming
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + buffer_bytes + b'\r\n')
    cap.release()

# Route to render the HTML template
@app.route('/')
def index():
    return render_template('index.html')
    # return redirect(url_for('video_feed')) #to render live stream directly

# Asynchronous function to handle offer exchange
async def offer_async():
    params = await request.json
    offer = RTCSessionDescription(sdp=params["sdp"], type=params["type"])

    # Create an RTCPeerConnection instance
    pc = RTCPeerConnection()

    # Generate a unique ID for the RTCPeerConnection
    pc_id = "PeerConnection(%s)" % uuid.uuid4()
    pc_id = pc_id[:8]

    # Create a data channel named "chat"
    # pc.createDataChannel("chat")

    # Create and set the local description
    await pc.createOffer(offer)
    await pc.setLocalDescription(offer)

    # Prepare the response data with local SDP and type
    response_data = {"sdp": pc.localDescription.sdp, "type": pc.localDescription.type}
    return jsonify(response_data)

# Wrapper function for running the asynchronous offer function
def offer():
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)

    future = asyncio.run_coroutine_threadsafe(offer_async(), loop)
    return future.result()

# Route to handle the offer request
@app.route('/offer', methods=['POST'])
def offer_route():
    return offer()
# Route to stream video frames
@app.route('/video_feed')
def video_feed():
    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')

def detestats():
    while True:
        my_stats = json.dumps(target_counts, default=convert_numpy_float)
        socketio.emit("target_stats", my_stats)
        socketio.sleep(1)

@socketio.on('connect')
def connect():
    # global thread
    # with thread_lock:
    #     if thread is None:
    socketio.start_background_task(detestats)

# Run the Flask app
if __name__ == "__main__":
    app.run(debug=True, host='0.0.0.0', threaded=True, port=5000)

Interface
<!DOCTYPE html>
<!-- Template by quackit.com -->
<html>

<head>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.0.1/socket.io.js"></script>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>Real-time video surveillance with automation and detection </title>
    <link rel="stylesheet" href="/static/style.css">

</head>

<body>

    <header id="Header">
        <div class="innertube">
            <p> ENHANCE AN INTELLIGENCE REAL-TIME VIDEO SURVEILLANCE SYSTEM WITH AUTOMATED DETECTION</p>
        </div>
        <h1>Real Time Video surveillance and Detection</h1>
    </header>
    <div class="innertube">

        <div id="video-feed">
            <img src="{{ url_for('video_feed') }}">
        </div>

        <div id="stats">
            <div id="person"></div>
            <div id="suspect"></div>
            <div id="vehicle"></div>
            <div id="animal"></div>
        </div>

    </div>

    <footer id="footer">
        <div class="innertube">
            <p>
                <center>University of KigaliK</center>
            </p>
        </div>
    </footer>
    <script src="static/main.js"></script>
</body>

</html>

